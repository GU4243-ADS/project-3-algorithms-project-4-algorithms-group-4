---
title: "Collaborative Filtering"
author: "Group 4"
date: "April 9, 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
setwd("/Users/Nicole/Documents/GitHub/project-3-algorithms-project-4-algorithms-group-4/doc")
#setwd("/Users/admin/Desktop/Columbia/Spring 2018/Applied DS/GitHub/project-3-algorithms-project-4-algorithms-group-4/doc")

load(file = "../data/MS_UI.RData")
load(file = "../data/movie_UI.RData")
```

```{r Matrix Calculations}
visit_nums <- rowSums(MS_UI, na.rm = TRUE)

# table(visit_nums)
# mean(visit_nums)
# median(visit_nums)

total_ratings <- rowSums(movie_UI, na.rm = TRUE)

# table(total_ratings)
# mean(total_ratings)
# median(total_ratings)
```


```{r Simularity Weights of the Users}
# Pearson correlations
load(file = "../data/MS_sim.RData")
load(file = "../data/movie_sim.RData")

# Spearman correlations

# Vector similarity (Cosine)

# Entropy-based

# Mean-square difference

# SimRank

```

```{r Calculating Predictions for Users}
# From Pearson Simularity Weights
load(file ="../data/MS_pred.RData")
load(file = "../data/movie_pred.RData")
```

Group 4:
- After calculating similarity weights, we select which other users' data are used in computing the predictions (currently, all of them).
- There is evidence that selecting a subset of users improves accuracy. 
- Moreover, when there are millions of users, using them all is infeasible. 

Explore: Will prediction accuracy improve if we select the best neighbors of the active user to use in calculating predictions?

# Model-based Algorithm
E-step math: $aic := log(\hat{\mu}) + \sum log(\gamma) - log(\sum e^{log (\mu) + \sum log (\gamma)})$

### EM train algo

```{r Model-Based Algorithm}
mov.train <- movie_UI # to clarify that this is training data, Note: the unrated user-movie combos are NA's
data <- mov.train[1:500, ] # subset for speed (until finished)

EM_train <- function(data, k, C = 5, tau = 0.01, ITER = 100){ 
  
  ############## Step 1 - Initial Conditions and Set up ####################
  
  data[which(is.na(data))] <- 0 #sets any NAs to 0s
  # Note: length(which(rowSums(data) == 0)) is 0 which means ther is extension on at least 1 dimension for each user, i.e. every user rated at least 1 movie
  C <- 12 # Half of the movie genres according to IMDB
  k = 6 # number of ratings
  n_users <- dim(data)[1]
  n_items <- dim(data)[2]
  
  users <- rownames(data)
  items <- colnames(data) # used items as a generic for both movies and vroots
  mu <- rep(1/C, C) # vector length C
  gamma <- array(1/k, dim = c(n_items, C, k)) # dims = items(movies), clusters, ratings
  #aic <- matrix(1/6, nrow = n_users, ncol = C) # cluster assignment/probability matrix, dims = users, clusters
  #gamma.norm <- gamma/mean(gamma)
  iter <- 1
  
  while(is.conv > tau | iter < ITER) {
   
  ######################### Step 2 - Expectation ####################
    

    pre_aic <- array(NA, c(k, length(users), C))
    gamma <- aperm(gamma, c(3, 1, 2)) # change dims to dims = (ratings, movies, clusters)
    gamma <- log(gamma) # logs gamma so we can use log sums instead of products
    for (i in 1:k) {
      temp <- apply(gamma, 3, function(x) x%*%t(data == i)) # each element of the kth row of resulting array represents the log sum (i.e. product) of movie-rating=i pairs of user i given class C. apply() outputs matrix with weird dims = (length(seq_along(\the result of the func on each sheet\)), number of sheets in third margin)
      temp <- array(temp, c(k, length(users), C)) # puts data in the correct shape. dims = (ratings, users, clusters)
      
      pre_aic[i,,] <- temp[i,,] # extract only the row for which the log sums over the correct subset of gammas_(k=i, j, c). dims = (ratings, users, clusters)
    }
    
    pre_aic <- t(colSums(pre_aic))  #  log sums over all ratings k the (previous) logsum of gammas of the j movies rated k=i, for each user i. dims = (C, i) # pre_aic is now the matrix of the part of the equation after the Pi in both the numerator and denominator for each C,i combination
    
    #pre_aic <- exp(pre_aic) # returns our expression to the non-logged world #^^^^^^^^
    
    #conclusion of above: basically took the logsum/product of all the movies rated 1 (then 2,...) for user i in cluster 1 wieghts, then log summed all those log sums over all ratings k for each user i
    aic_numer <- log(mu) + pre_aic # gives the numerator of aic. dims = (C, i) #I am assuming C clusters are still oriented 1:C in the same order in both mu and pre_aic
    #^^^^^^^^^ is logging then adding (not multiplying) mu the right thing to do?
    
    aic_numer <- t(aic_numer) # dims = (users, Clusters)
    
    aic_denom <- log(rowSums(exp(aic_numer)))  # every user gets the same denom over all the clusters (here: 1 cluster = 1 row). dims = vector length(users)
    #^^^^^^^^^^^^^^ here I am exp'ing the numer to return to the non-logged world, summing as demanded to produce denom, then logging that denom to be compatible with the logged state of the numer
    
    #aic <- aic_numer/aic_denom #^^^^^^^^ # dims = (users, clusters) # NaNs introduced.... :(
    aic <- aic_numer - aic_denom #^^^^^^^^^^^ this is equivalent to dividing because I am subtracting two logged entities.
    # but isn't aic really logged(aic) now.... so won't it be incompatible with my processes in the M-step...???
    aic <- exp(aic) # not logged anymore
    
  ######################## Step 3 - Maximization #########################
 
  ## Estimate Mu 
  mu <- apply(aic, 2, sum)/length(users) # vector of cluster shares/probabilities
  
  ## Estimate Gamma
  
  #gamma <- function() { # this is func is just diagnostic while I am still coding
  
  indicator.numer <- array(0, dim = c(length(users),length(items), k))
  indicator.denom <- matrix(0, nrow = length(users), ncol = length(items))
    
  for (i in 1:k) 
    # can this be done with an apply appoach? yes, apply and margin = 3? but how to use apply with multiple funcs and subsetting, maybe define a func like below?
    {
      indicator.numer[,,i][which(data == i)] <- 1 # indicator array to identify each instance in which user i rated movie j with rating k
    }
  indicator.numer <- aperm(indicator.numer, c(2,1,3)) # transposing so that the matrix is conformable to aic. new dims = (movies/items, users, ratings)
  # would transposing each sheet in the for loop be faster?
  # maybe faster to transpose aic rather than aperm indicator.nomin
   
  numer <- apply(indicator.numer, 3, function(x) x%*%aic) # each element of resulting array represents the sum of the class C aic wieghts of every user who rated that jth movie with that rating k. apply() outputs matrix with weird dims = (length(seq_along(\the result of the func on each sheet\)), number of sheets in third margin)
  numerator <- array(numer, c(length(items), C, k)) # puts data in the correct shape. dims = (movies, clusters, ratings) 
  
  
  indicator.denom[which(data != 0)] <- 1 # indicator array to identify each instance in which user i rated movie j with any rating
  indicator.denom <- t(indicator.denom) # dims = movies, users. 
  denominator <- indicator.denom%*%aic # each element of the resulting matrix represents the sum of the class C aic weights of every user who rated movie j with any rating. dims = (movies, clusters). Note: denominator is common across ratings k, but not across clusters, there for the following code would be unecessary: denominator <- apply(indicator.denom, 3, function(x) x%*%aic)
  
  #result <- nominator/denominator # dims = movies, clusters, ratings
  result <- apply(numerator, 3, function(x) x/denominator) # divides each numerator element by its respective denominator value. apply() returns a weirdly shaped matrix again.
  gamma <- array(result, c(length(items), C, k)) # puts data in the correct shape. dims = (movies, clusters, ratings)
  #gamma
#} # end of the diagnostic func
#system.time(new <- gamma())
#rowSums(aperm(new, c(1, 3, 2))[,,1]) # this sums over k's for each movie. The sums should equal 1. They do!!!  but I have some NaNs which are introduced when I divide the numerator by the denominator. ... what to do... logs...? just set them to 0?? 
  
  # FIX NaNs: log the numerator and the denominator then subtract. 
  
  ################# Step 4 - Convergence Conditions using l-2 norm ###############
  is.conv <- norm(aic - aic_pre, type = "2") # measure of the change in cluster assignments

  aic_pre <- aic
  iter = iter + 1
  }
  
  ### Hard Assignment
  hard.assignments <- (aic == rowMaxs(aic)) + 0 # I used a function from "MatrixsStats" library
  #hard.cluster <- apply(aic, 1, which.max) # hard cluster assignments
  return(list("hard.assignments" = hard.assignments, "gamma" = gamma, "mu" = mu))
}


```

### Predict function
```{r}

###########
### Inputs:
# active.users = the test data user-item matrix
# hard.assignments = the hard.assignments output from the EM_train func

  hard.assignments <- matrix(0, nrow = n.users, ncol = C)
  hard.assignments[, 5] <- rep(1, n.users)


bayesian_predict <-function(data, j,  hard.assignments, gamma){
  n.users <- dim(data)[1]


  predict.rank <- matrix(0, nrow = n.users)
    for (k in 1:6){
      predict.rank <- predict.rank + k * hard.assignments %*% gamma[C, , k] 
    }
  }


n.items <- dim(mov.train)[2]
  
for (j in 1:n.items) {
mov.train[, j] <- bayesian_predict(mov.train, j, hard.assignments, gamma)
}
# says items are not of the same length -- confused mov.train[, j] has length 5055 and length(predict.rank) = 5055
```

Notes to make predictions from EM: 
- After the termination of the EM algorithm, give a hard assignment of clusters (EM algorithm only gives soft assignment so use the highest probability that a user falls within a specific cluster to create hard assignment)
- For each movie-cluster pair, you have a multinomial distribution (this is $\gamma$); use this probability distribution to calculate the rating that each user \textit{a} gave to movie \textit{m} within each cluster \textit{c}. 
- All of the users within each cluster have the same rating probability.

Predict rank function: 
\[r_{a, m} = \sum_{k=1}^6 k \frac{\sum_{c=1}^C \mu_c \gamma_{m,c}^k \prod_{j\in I(a)} \gamma_{j,c}^{r_{a,j}}}{\sum_{c=1}^C \mu_c \prod_{j\in I(a)} \gamma_{j,c}^{r_{a,j}}}\]


### Test error
```{r}
what.to.predict <- which(!is.na(movies_UI_test))

(mse <- sum((predictions[what.to.predict] - movie_UI_test[what.to.predict])**2)/length(what.to.predict))
(mae <- sum(abs(predictions[what.to.predict] - movie_UI_test[what.to.predict]))/length(what.to.predict))

R2.numer <- 1 - sum((predictions[what.to.predict] - movies_UI_test[what.to.predict])**2)
R2.denom <- sum((movies_UI_test[what.to.predict] - mean(movies_UI_test[what.to.predict]))**2)

(R2 <- R2.numer/R2.denom)
```


For individual scoring, we look at the average absolute deviation of the predicted vote to the actual vote on items the users in the test set have actually voted on. That is, if the number of predicted votes in the test set for the active case is ma, then the average absolute deviation for a user is: $S_a = \frac{1}{m_a} \sum_{j \in P_a} | p_{a,j} - v_{a,j}|$ where $p_{a,j}$ is the prediction and $v_{a,j} is the validation. 

Furthermore, we make an estimate of how likely it is that the user will visit an item on a ranked list. We posit that each successive item in a list is less likely.to be viewed by the user with an exponential decay. Then the expected utility of a ranked list of items (sorted by index j in order of declining vaj) is: $R_a = \sum_{j} \frac{max(v_{a,j} - d, 0)}{2^{(j-1)/(\alpha - 1)}}$ where d is the neutral vote and $\alpha$ is the viewing halflife. The halflife is the number of the item on the list such that there is a 50-50 chance the user will review that item. For these experiments, we used a halflife of 5 items.


```{r}
### Alternate M-step
###### What is this?? it looks like a much more efficient M-step :).. It is kind of genius in its efficiency.. I tried to limit what was inside the for loop but this is elegant because correctly identifies that what makes the code slow is the number of iterations more than the amount of code within the iterations so it puts steps thing in the loop I left out of it.
  
  for (i in 1:k){
    gamma.numer[, , ] <- (aic) %*% (movie == k)
    gamma.denom[, , ] <- colSums(gamma.numer)

    gamma <- gamma.numer/gamma.denom
  }


################# old beginnings of E-step
library(matrixStats)

    e.step1 <- log(mu) + log(gamma) # numerator of aic using log probabilities
    for (j in 1:length(items)){ 
      
    e.step2 <- logSumExp(log(mu) + log(gamma.sum)) # normalizing 
    aic <- e.step1 - e.step2 
    }

 # in the numerator we multiply all gamma[c,j,k] for a given class c, all movies j that have been rated by the active user, k being the rating that the active user actually gave to this movie ? And in the denominator sum all such products for all classes ?
    
    # logSumExp(vector of probabilities?) -- the step where a_ic = max c
    # The usual way to handle this is to work with log-probabilities instead of probabilities. This allows us to handle very small numbers without problem. When applying logs to the formula, the only difficulty is then dealing with the denominator that contains a sum.
  
    
```


```{r}
mov.train <- movie_UI # to clarify that this is training data, Note: the unrated user-movie combos are NA's
data <- mov.train[1:500, ] # subset for speed (until finished)

EM_train <- function(data, k, C = 5, tau = 0.01, ITER = 100){ 
  
  ############## Step 1 - Initial Conditions and Set up ####################
  
  data[which(is.na(data))] <- 0 #sets any NAs to 0s
  # Note: length(which(rowSums(data) == 0)) is 0 which means ther is extension on at least 1 dimension for each user, i.e. every user rated at least 1 movie
  C <- 12 # Half of the movie genres according to IMDB
  k = 6 # number of ratings
  n.users <- dim(data)[1]
  n.items <- dim(data)[2]
  
  users <- rownames(data)
  items <- colnames(data) # used items as a generic for both movies and vroots
  mu <- rep(1/C, C) # vector length C
  gamma <- array(1/k, dim = c(n_items, C, k)) # dims = items(movies), clusters, ratings
  #aic <- matrix(1/6, nrow = n_users, ncol = C) # cluster assignment/probability matrix, dims = users, clusters
  #gamma.norm <- gamma/mean(gamma)
  iter <- 1
  
  aic <- matrix(NA, nrow = n.users, ncol = C)
  
  while(is.conv > tau | iter < ITER) {
    
    ## Expectation Step
    for(i in 1:n.users){
      rank = na.omit(mov.train[i, ])
      for(c in 1:C) {
        for(k in 1:6){
          aic[i, c] <- aic[i, c]*gamma[c, mov.train[i, k], rank[k]]
        }
      }
    }
    
    
    ## Convergence Check
    is.conv <- norm(aic - aic_pre, type = "2") # measure of the change in cluster assignments

  aic_pre <- aic
  iter = iter + 1
  }
```


Try simplifying the sum and exponential to see that it is the same equation as in the last two slides. It is easy to run into underflow problem when dealing with these probabilities that are very small. You can see the answers in @104 to see how to deal with it (the usual strategy is to use log-probabilities instead).


Model-based recommendation intermediate steps:
-(E-step) Write code to give cluster assignment probabilities to user, a matrix where cols are clusters and rows are users. output = assignment probability matrix.

-(M- Step) Write code to re-estimate mu and gamma vectors from each users cluster assignment probabilities. There are $k*C*j$ gamma values which can be put into a 3d array or a series of matrices. Output = recalculated mu and gamma (matrix).

- Write code to (a) iterate over the the two steps, (b) to set when to stop iteration(consider iteration back stop number), (c) set up initial $\mu_c$ and $\gamma_{j,C,k}$ and other values, and (d) make "hard" cluster assignments from the "soft" assignments of the final iteration of EM. Also, do we do uniform dist. initial values or do we do random initial values and choose best result (more complicated.. we can test to see if it even makes a difference)

-Write code to calculate expected active user rating from EM parameters. Output = function with input of data and # of classes and output of predicted rating on movie m for active user.

-Write CV code to determine best test error on predictions at different numbers of classes for the EM/predictor model. Include code to calculate test error (shared with memory-based team). Q: do we evaluate CV based on log likelihood of the EM model or the test error of the prediction model? Output = optimal number of classes. 

-Re calibrate for microsoft data.


Notes on EM: 
- Use cross-validation to find optimal number of clusters (if computationally taxing, then use a k-fold CV where k = 1)
- Terminate when if iter = 10000 or if $\sum_{c = 1}^C |{\hat{\mu}_c^{t+1} - \hat{\mu}_c^{t}}|^2$ where |x| is the l-2 norm. 
- Can do random initializations and find log-likelihood but not necessary


In case neighbors isn't done... 
```{r}
selectNeighborWeights <- function(df, weights, n){
  users <- rownames(df)
  m <- length(users)
  neighbors <- matrix(rep(NA, m * n), m, n)
  neighors <- data.frame(neighbors)
  rownames(neighbors) <- users
  
  for (i in 1:m){
    neighbors[i, ] <- colnames(weights)[order(weights[i, ], decreasing=TRUE)][1:n]
  }
  return (neighbors)
}
```



