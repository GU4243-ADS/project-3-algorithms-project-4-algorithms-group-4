---
title: "Collaborative Filtering"
author: "Group 4"
date: "4/8/2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### Step 0: Load Data
```{r}
# setwd("/Users/Nicole/Documents/GitHub/project-3-algorithms-project-4-algorithms-group-4/doc")
# Change working directory 


have <- intersect(installed.packages()[,1], c("matrixStats"))
need <- setdiff(c("matrixStats"), have)
install.packages(need)

load(file = "../data/MS_UI.RData")
load(file = "../data/movie_UI.RData")

# movie_train <- read.csv("../data/eachmovie_sample/data_train.csv")
# movie_test <- read.csv("../data/eachmovie_sample/data_test.csv")
# MS_train <- read.csv("../data/MS_sample/data_train.csv")
# MS_test <- read.csv("../data/MS_sample/data_test.csv")

```

#### Transformation
Convert the original dataset to a matrix which rows represents users and columns represents items

```{r}
# movie_UI <- movie_data_transform(movie_train)
# movie_test <- movie_data_transform(movie_test)

# MS_UI <- MS_data_transform(MS_train)
# MS_test <- MS_data_transform(MS_test)

load(file ="../data/MS_UI.RData")
load(file ="../data/MS_test.RData")
load(file ="../data/movie_UI.RData")
load(file ="../data/movie_test.RData")
```

## Task: Memory Based Collaborative Filtering

### Calculate similarity weights 
#### Pearson correlation
```{r}
# Weights
# web_pearson <- all_weight(MS_UI, 'pearson')
# movie_pearson <- all_weight(movie_UI, 'pearson')

web_pearson <- readRDS(file = "../output/web_pearson.RData")
movie_pearson <- readRDS(file = "../output/movie_pearson.RData")
```

#### Spearman's correlation
```{r}
# Weights
# web_spearman <- all_weight(MS_UI, 'spearman')
# movie_spearman <- all_weight(movie_UI, 'spearman')

web_spearman <- readRDS(file = "../output/web_spearman.RData")
movie_spearman <- readRDS(file = "../output/movie_spearman.RData")
```

#### Vector similarity
```{r}
# Weights
# web_vector <- all_weight(MS_UI, 'vector')
# movie_vector <- all_weight(movie_UI, 'vector')

web_vector <- readRDS(file = "../output/web_vector.RData")
movie_vector <- readRDS(file = "../output/movie_vector.RData")
```

#### Mean-Square Difference
```{r}
# Weights
# weights_MSD_train_MS <- meanSquareDiff(MS_train)
# weights_MSD_train_Movie <- meanSquareDiff(Movie_train)

weights_MSD_train_MS <- readRDS(file = "../output/weights_MSD_train_MS.RData")
weights_MSD_train_Movie <- readRDS(file = "../output/weights_MSD_train_Movie.RData") waiting!!!
```


#### SimRank
```{r}
# Weights
# weights_usersim_train_Movie <- simrank(movie_UI)

weights_usersim_train_Movie <- load(file = "../output/weights_usersim_train_Movie.RData") waiting!!!
```

### Prediction for each weight similarity

```{r}
# pearson
# pred_web_pearson <- pred_matrix(MS_UI, web_pearson)
load()
# pred_movie_pearson <- pred_matrix(movie_UI, movie_pearson)
load()

#spearman
# pred_web_spearman <- pred_matrix(MS_UI, web_spearman)
load()
# pred_movie_spearman <- pred_matrix(movie_UI, movie_spearman)
load()

#vector (cosine)
# pred_web_vector <- pred_matrix(MS_UI, web_vector)
load()
# pred_movie_vector <- pred_matrix(movie_UI, movie_vector)
load()

#meansquare
# pred_web_meansquare <- pred_matrix(MS_UI, weights_MSD_train_MS)
load(file ="../output/weights_MSD_train_MS_pred.RData")
# pred_movie_meansquare <- pred_matrix(movie_UI, weights_MSD_train_Movie)
load(file = "../output/weights_MSD_train_Movie_pred.RData")

# Predictions
# pred_movie_simrank <- pred_matrix(movie_UI, weights_usersim_train_Movie)
load(file = "../output/weights_usersim_train_Movie_pred.RData")
```

## Task: Group 4 Specific Assignment - Neighbors 
```{r}

```

## Task: Model Based Collaborative Filtering

### Step 1: Build EM algorithm 
E-step: $aic := log(\hat{\mu}) + \sum log(\gamma) - log(\sum e^{log (\mu) + \sum log (\gamma)})$

M-step: $\hat{\mu}_c = \frac{1}{N} \sum_{i = 1}^N a_{ic} \text{for} c = 1, 2, ... , C$  
$\hat{gamma}_{c,j}^{k} = \frac{\sum_{i|j \in I(i)} a_{ic}(r_{i,j} = k})}{\sum_{i|j \in I(i)} a_{ic}} \text{for } c, j, k$. 
```{r}
## Initialize parameters


## E-step


## M-step
```


### Step 2: Cross validation to choose the best number of clusters
```{r}

```


### Step 3: Predict ratings
```{r}

```

<<<<<<< HEAD
### Step 3: Calculate test error
=======

### Step 4: Calculate test error
>>>>>>> 61a4ead2b7071ce53d32c63cc038e8732da228ac
```{r}

```

