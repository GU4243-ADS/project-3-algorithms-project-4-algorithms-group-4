setwd("~/Documents/GitHub/Spring2018/Project_Starter_Codes/Project2-PredictiveModelling/doc")
knitr::opts_chunk$set(echo = TRUE)
library("EBImage")
library("gbm")
img_train_dir  <- "../../../../Proj2_Data/train/" # This is where my data lives (outside of Spring2018)
n_files <- length(list.files(img_train_dir))
n_files
list.files(img_train_dir)
length(list.files(img_train_dir))
n_files <- length(list.files(img_train_dir))
n_files
dat <- matrix(NA, nrow = n_files, ncol = 3)
for(i in 1:n_files){
img <- readImage(paste0(img_train_dir,  "pet", i, ".jpg"))
dat[i, 1:length(dim(img))] <- dim(img)
}
# How many B/W images?  All color.
table(dat[, 3])
# How many rows? A lot at 500 rows.  Maybe a good subset to consider.
table(dat[, 1])
cv.function <- function(X.train, y.train, d, K) {
n        <- length(y.train)
n.fold   <- floor(n/K)
s        <- sample(rep(1:K, c(rep(n.fold, K-1), n-(K-1)*n.fold)))
cv.error <- rep(NA, K)
for (i in 1:K){
train.data  <- X.train[s != i,]
train.label <- y.train[s != i]
test.data   <- X.train[s == i,]
test.label  <- y.train[s == i]
par  <- list(depth = d)
fit  <- train(train.data, train.label, par)
pred <- test(fit, test.data)
cv.error[i] <- mean(pred != test.label)
}
return(c(mean(cv.error), sd(cv.error)))
}
model_values <- seq(3, 11, 2)
model_labels <- paste("GBM with depth =", model_values)
la
lab
n_r    <- 500
subset <- which(dat[,1] == n_r)
### store vectorized pixel values of images
dat <- matrix(NA, length(subset), n_r)
for(i in subset){
img     <- readImage(paste0(img_train_dir,  "pet", i, ".jpg"))
dat[i,] <- rowMeans(img)
}
i
rowMeans(img)
n_r    <- 500
subset <- which(dat[,1] == n_r)
### store vectorized pixel values of images
dat <- matrix(NA, length(subset), n_r)
row <- 1
for(i in subset){
img     <- readImage(paste0(img_train_dir,  "pet", i, ".jpg"))
dat[row,] <- rowMeans(img)
row <- row + 1
}
label_train <- read.csv("../../../../Proj2_Data/train_label.txt", header = F)
label_train <- read.csv("../../../../Proj2_Data/train_label.txt", header = F)
label_train <- as.numeric(unlist(label_train) == "cat")
label_train
label_train <- label_train[subset]
dim(da)
dim(dat)
n_r    <- 500
subset <- which(dat[,1] == n_r)
### store vectorized pixel values of images
dat <- matrix(NA, length(subset), n_r)
row <- 1
dat
dim(dat)
n_files <- length(list.files(img_train_dir))
### store image dimensions
dat <- matrix(NA, nrow = n_files, ncol = 3)
for(i in 1:n_files){
img <- readImage(paste0(img_train_dir,  "pet", i, ".jpg"))
dat[i, 1:length(dim(img))] <- dim(img)
}
# How many B/W images?  All color.
table(dat[, 3])
# How many rows? A lot at 500 rows.  Maybe a good subset to consider.
table(dat[, 1])
n_r    <- 500
subset <- which(dat[,1] == n_r)
### store vectorized pixel values of images
dat <- matrix(NA, length(subset), n_r)
row <- 1
dim(dat)
for(i in subset){
img     <- readImage(paste0(img_train_dir,  "pet", i, ".jpg"))
dat[row,] <- rowMeans(img)
row <- row + 1
}
model_values <- seq(3, 11, 2)
model_labels <- paste("GBM with depth =", model_values)
label_train <- read.csv("../../../../Proj2_Data/train_label.txt", header = F)
label_train <- as.numeric(unlist(label_train) == "cat")
label_train <- label_train[subset]
length(label_train)
err_cv <- array(dim = c(length(model_values), 2))
for(k in 1:length(model_values)){
cat("k=", k, "\n")
err_cv[k,] <- cv.function(dat, label_train, model_values[k], K)
}
K <- 5
err_cv <- array(dim = c(length(model_values), 2))
for(k in 1:length(model_values)){
cat("k=", k, "\n")
err_cv[k,] <- cv.function(dat, label_train, model_values[k], K)
}
K <- 5
err_cv <- array(dim = c(length(model_values), 2))
for(k in 1:length(model_values)){
cat("k=", k, "\n")
err_cv[k,] <- cv.function(dat, label_train, model_values[k], K)
}
train <- function(dat_train, label_train, par = NULL){
### Train a Gradient Boosting Model (GBM) using processed features from training images
### Input:
###  -  processed features from images
###  -  class labels for training images
### Output: training model specification
### load libraries
library("gbm")
### Train with gradient boosting model
if(is.null(par)){
depth <- 3
} else {
depth <- par$depth
}
fit_gbm <- gbm.fit(x = dat_train, y = label_train,
n.trees = 2000,
distribution = "bernoulli",
interaction.depth = depth,
bag.fraction = 0.5,
verbose = FALSE)
best_iter <- gbm.perf(fit_gbm, method = "OOB", plot.it = FALSE)
return(list(fit = fit_gbm, iter = best_iter))
}
K <- 5
err_cv <- array(dim = c(length(model_values), 2))
for(k in 1:length(model_values)){
cat("k=", k, "\n")
err_cv[k,] <- cv.function(dat, label_train, model_values[k], K)
}
source("../lib/cross_validation.R")
source("../lib/train.R")
source("../lib/test.R")
model_values <- seq(3, 11, 2)
model_labels <- paste("GBM with depth =", model_values)
label_train <- read.csv("../../../../Proj2_Data/train_label.txt", header = F)
label_train <- as.numeric(unlist(label_train) == "cat")
label_train <- label_train[subset]
K <- 5
err_cv <- array(dim = c(length(model_values), 2))
for(k in 1:length(model_values)){
cat("k=", k, "\n")
err_cv[k,] <- cv.function(dat, label_train, model_values[k], K)
}
warnings()
plot(model_values, err_cv[,1], xlab = "Interaction Depth", ylab = "CV Error",
main = "Cross Validation Error", type = "n", ylim = c(0, 0.25))
points(model_values, err_cv[,1], col = "blue", pch=16)
lines(model_values, err_cv[,1], col = "blue")
arrows(model_values, err_cv[,1] - err_cv[,2], model_values, err_cv[,1] + err_cv[,2],
length = 0.1, angle = 90, code = 3)
err_cv[,1]
err_cv
model_best <- model_values[1]
if(run.cv){
model_best <- model_values[which.min(err_cv[, 1])]
}
par_best <- list(depth = model_best)
model_best <- model_values[which.min(err_cv[, 1])]
par_best <- list(depth = model_best)
par_best
tm_train <- NA
tm_train <- system.time(fit_train <- train(dat_train, label_train, par_best))
tm_train <- NA
tm_train <- system.time(fit_train <- train(dat, label_train, par_best))
setwd("/Users/admin/Desktop/Columbia/Spring 2018/Applied DS/GitHub/Personal-Repo-ADS-Spring-2017")
ms.train <- read.csv("../MS_sample/data_train.csv")
setwd("/Users/admin/Desktop/Columbia/Spring 2018/Applied DS/GitHub/project-3-algorithms-project-4-algorithms-group-4/data/MS_sample/")
ms.train <- read.csv("../MS_sample/data_train.csv")
setwd("/Users/admin/Desktop/Columbia/Spring 2018/Applied DS/GitHub/project-3-algorithms-project-4-algorithms-group-4/data/MS_sample")
ms.train <- read.csv("../MS_sample/data_train.csv")
ms.train <- read.csv("../data_train.csv")
setwd("/Users/admin/Desktop/Columbia/Spring 2018/Applied DS/GitHub/project-3-algorithms-project-4-algorithms-group-4/data/MS_sample/")
ms.train <- read.csv("../data_train.csv")
setwd("/Users/admin/Desktop/Columbia/Spring 2018/Applied DS/GitHub/project-3-algorithms-project-4-algorithms-group-4/data/MS_sample/")
ms.train <- read.csv("../data_train.csv")
setwd("/Users/admin/Desktop/Columbia/Spring 2018/Applied DS/GitHub/project-3-algorithms-project-4-algorithms-group-4/data/MS_sample")
ms.train <- read.csv("../data_train.csv")
ms.train <- read.csv("../MS_sample/data_train.csv")
setwd("/Users/admin/Desktop/Columbia/Spring 2018/Applied DS/GitHub/project-3-algorithms-project-4-algorithms-group-4/data/MS_sample")
ms.train <- read.csv("../MS_sample/data_train.csv")
tm_train <- system.time(fit_train <- train(dat, label_train, par_best))
setwd("/Users/admin/Desktop/Columbia/Spring 2018/Applied DS/GitHub/project-3-algorithms-project-4-algorithms-group-4/data/MS_sample")
ms.train <- read.csv("../MS_sample/data_train.csv")
setwd("/Users/admin/Desktop/Columbia/Spring 2018/Applied DS/GitHub/project-3-algorithms-project-4-algorithms-group-4/data/MS_sample/")
test <- read.csv("../MS_sample/data_train.csv")
ms.train <- read.csv("../MS_sample/data_train.csv")
setwd("/Users/admin/Desktop/Columbia/Spring 2018/Applied DS/GitHub/project-3-algorithms-project-4-algorithms-group-4/data/MS_sample/")
ms.train <- read.csv("../MS_sample/data_train.csv")
ms.train <- read.csv("data_train.csv")
setwd("/Users/admin/Desktop/Columbia/Spring 2018/Applied DS/GitHub/project-3-algorithms-project-4-algorithms-group-4/data/MS_sample/")
ms.train <- read.csv("../MS_sample/data_train.csv")
setwd("/Users/admin/Desktop/Columbia/Spring 2018/Applied DS/GitHub/project-3-algorithms-project-4-algorithms-group-4/data/MS_sample/")
bob <- read.csv("../MS_sample/data_train.csv")
bob <- read.csv("../MS_sample/data_train.csv")
setwd("/Users/admin/Desktop/Columbia/Spring 2018/Applied DS/GitHub/project-3-algorithms-project-4-algorithms-group-4/data/MS_sample/")
bob <- read.csv("../MS_sample/data_train.csv")
ms.train <- read.csv("../MS_sample/data_train.csv")
head(ms.train)
head(ms.train,40)
?sort
?which
which(ms.train$V1 == "C")
M <-  matrix( c(2,6,5,1,10,4), nrow = 2,ncol = 3,byrow = TRUE)
M
t(M)
M %*% t(M)
?seq
ll <- c(TRUE, FALSE, TRUE, NA, FALSE, FALSE, TRUE)
seq(ll)
( m <- matrix(1:12, 3, 4) )
div.3 <- m %% 3 == 0
which(div.3)
which(div.3, arr.ind = TRUE)
div.3
m <- matrix(1:12, 3, 4, byrow = TRUE)
div.3 <- m %% 3 == 0
m
div.3
which(div.3)
setwd("/Users/admin/Desktop/Columbia/Spring 2018/Applied DS/GitHub/project-3-algorithms-project-4-algorithms-group-4/data/eachmovie_sample/")
ms.train <- read.csv("../eachmovie_sample/data_train.csv")
setwd("/Users/admin/Desktop/Columbia/Spring 2018/Applied DS/GitHub/project-3-algorithms-project-4-algorithms-group-4/data/MS_sample/")
ms.train <- read.csv("../MS_sample/data_train.csv")
setwd("/Users/admin/Desktop/Columbia/Spring 2018/Applied DS/GitHub/project-3-algorithms-project-4-algorithms-group-4/data/eachmovie_sample/")
mov.train <- read.csv("../eachmovie_sample/data_train.csv")
mode(mov.train)
class(mov.train)
typeof
typeof(mov.train)
head(mov.train, 20)
?order
?all
a <- c(1:10)
a
b <- c(1:10)
a == b
all(a == b)
b[5] <- 0
b
all(a == b)
a == b
knitr::opts_chunk$set(echo = TRUE)
setwd("/Users/Nicole/Documents/GitHub/project-3-algorithms-project-4-algorithms-group-4/doc")
load(file = "../data/MS_UI.RData")
load(file = "../data/movie_UI.RData")
setwd("/Users/admin/Desktop/Columbia/Spring 2018/Applied DS/GitHub/project-3-algorithms-project-4-algorithms-group-4/doc")
load(file = "../data/MS_UI.RData")
load(file = "../data/movie_UI.RData")
head(MS_UI_test)
load("/Users/admin/Desktop/Columbia/Spring 2018/Applied DS/GitHub/project-3-algorithms-project-4-algorithms-group-4/data/movie_pred.RData")
head(movie_UI)
m
m[,-2]
m[,-2:3]
m[,-(2:3)]
setwd("/Users/admin/Desktop/Columbia/Spring 2018/Applied DS/GitHub/project-3-algorithms-project-4-algorithms-group-4/doc")
load(file = "../data/MS_UI.RData")
load(file = "../data/movie_UI.RData")
load(file = "../data/movie_UI.RData")
View(movie_UI)
unique(mov.train$User)
length(unique(mov.train$User))
dim(movie_UI)
length(unique(mov.train$Movie))
mov.train <- movie_UI
?vector
?array
class(mov.train)
mode(mov.train)
typeof(mov.train)
str(mov.train)
min(mov.train)
?min
unique(mov.train)
head(mov.train)
str(mov.train)
mov.train[20,20]
mov.train[20,21]
mov.train[20,22]
min(mov.train, na.rm = TRUE)
max(mov.train, na.rm = TRUE)
?range
range(mov.train, na.rm = TRUE)
mu <- vector(mode = "double", length = C)
#### Step 1 - Initialization ####
#data <- movie_UI[1:500, ] # subset for speed (until finished)
C <- 12 # Half of the movie genres according to IMDB
mu <- vector(mode = "double", length = C)
#### Step 1 - Initialization ####
data <- mov.train[1:500, ] # subset for speed (until finished)
gamma <- array(0, dim = c(nrow(data), k, C))
k = 6
gamma <- array(0, dim = c(nrow(data), k, C))
?matrix
head(colnames(mov.train))
head(rownames(mov.train))
users <- rownames(mov.train)
tail(colnames(mov.train))
users <- rownames(mov.train)
movies <- colnames(mov.train)
str
str(users)
class
class(users)
mode(users)
typeof(users)
length(users)
?apply(array, margin, ...)
x <- cbind(x1 = 3, x2 = c(4:1, 2:5))
x
apply(x, 2, mean, trim = .2)
apply(x, 1, mean, trim = .2)
