l <- list(log_lik(post), log_lik(post2))
w <- loo_model_weights(l)
library(loo)
w <- loo_model_weights(l)
library(loo)
library(devtools)
devtools::install_github('stan-dev/loo', ref = 'new-psis-vignette')
library(loo)
.libPaths()
library(devtools)
devtools::install_github('stan-dev/loo', ref = 'new-psis-vignette')
library(loo)
remove.packages(loo, "/Library/Frameworks/R.framework/Versions/3.4/Resources/library/")
remove.packages(loo, /Library/Frameworks/R.framework/Versions/3.4/Resources/library/)
remove.packages(loo, /Library/Frameworks/R.framework/Versions/3.4/Resources/library)
remove.packages(loo, '/Library/Frameworks/R.framework/Versions/3.4/Resources/library')
remove.packages('loo', '/Library/Frameworks/R.framework/Versions/3.4/Resources/library')
install.packages("loo")
library(loo)
l <- list(log_lik(post), log_lik(post2))
w <- loo_model_weights(l)
devtools::install_github('stan-dev/loo', ref = 'new-psis-vignette')
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
library(rstan)
library(rstanarm); options(mc.cores = parallel::detectCores())
library(bridgesampling)
library(projpred)
library(bayesplot)
library(devtools)
devtools::install_github('stan-dev/loo', ref = 'new-psis-vignette')
set.seed(2184)
hsbcl <- foreign::read.dta("https://stats.idre.ucla.edu/stat/stata/webbooks/logistic/hsbcl.dta")
colnames(hsbcl)
X <- model.matrix(honcomp ~ race + ses + write + math + science, hsbcl)[, -1]
expose_stan_functions("hsbcl_rng.stan")
test <- hsbcl_rng(S = 100, X = X)
test[1, ]
post <- stan_clogit(honcomp ~ as.factor(race) + as.factor(ses) + write + math + science, data = hsbcl, strata = pid, diagnostic_file = file.path(getwd(), "clogit.csv"))
print(post)
plot(post)
bayesplot::mcmc_dens(as.matrix(post), regex_pars = "science") # ask about regex_pars
gg <- pp_check(post, plotfun = "dens_overlay", nreps = 10) +
ggplot2::theme(legend.position = "bottom")
PPD <- posterior_predict(post, draws = 1000)
lower <- apply(PPD, MARGIN = 2, quantile, probs = 0.25)
upper <- apply(PPD, MARGIN = 2, quantile, probs = 0.75)
with(hsbcl, mean(honcomp[ses == "low"] > lower &
honcomp[ses == "low"] < upper)) #what variable to take the mean of?
post2 <- stan_clogit(honcomp ~ race + hises + academic, data = hsbcl, strata = pid, diagnostic_file = file.path(getwd(), "clogit.csv"))
l <- list(log_lik(post), log_lik(post2))
w <- loo_model_weights(l)
l <- list(log_lik(post), log_lik(post2))
w <- loo_model_weights(l)
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
library(rstan)
library(rstanarm); options(mc.cores = parallel::detectCores())
library(bridgesampling)
library(projpred)
library(bayesplot)
set.seed(2184)
library(loo)
hsbcl <- foreign::read.dta("https://stats.idre.ucla.edu/stat/stata/webbooks/logistic/hsbcl.dta")
colnames(hsbcl)
X <- model.matrix(honcomp ~ race + ses + write + math + science, hsbcl)[, -1]
post <- stan_clogit(honcomp ~ as.factor(race) + as.factor(ses) + write + math + science, data = hsbcl, strata = pid, diagnostic_file = file.path(getwd(), "clogit.csv"))
```{r}
print(post)
plot(post)
bayesplot::mcmc_dens(as.matrix(post), regex_pars = "science") # ask about regex_pars
gg <- pp_check(post, plotfun = "dens_overlay", nreps = 10) +
ggplot2::theme(legend.position = "bottom")
gg <- pp_check(post, plotfun = "dens_overlay", nreps = 10) +
ggplot2::theme(legend.position = "bottom")
gg
post2 <- stan_clogit(honcomp ~ race + hises + academic, data = hsbcl, strata = pid, diagnostic_file = file.path(getwd(), "clogit.csv"))
gg <- pp_check(post, plotfun = "dens_overlay", nreps = 50) +
ggplot2::theme(legend.position = "bottom")
gg
l <- list(log_lik(post), log_lik(post2))
w <- loo_model_weights(l)
compare_models(loo(post), loo(post2))
post2 <- stan_clogit(honcomp ~ as.factor(race) + as.factor(hises) + academic, data = hsbcl, strata = pid, diagnostic_file = file.path(getwd(), "clogit.csv"))
length(PPD)
PPD <- posterior_predict(post, draws = 1000)
length(PPD)
dim(PPD)
View(PPD)
plot(post)
ROOT <- "https://archive.ics.uci.edu/ml/machine-learning-databases/"
crime <- read.csv(paste0(ROOT, "communities/communities.data"),
header = FALSE, na.strings = "?")
colnames(crime) <- read.table(paste0(ROOT, "communities/communities.names"),
skip = 75, nrows = ncol(crime))[,2]
post_crime <- stan_lm(ViolentCrimesPerPop ~ population + racepctblack + agePct12t29 + medIncome + NumUnderPov + PctUnemployed + MalePctDivorce + PctWorkMom + HousVacant + NumStreet + PolicReqPerOffic + PolicCars + NumKindsDrugsSeiz +  agePct12t29*PctUnemployed + agePct12t29^2, data = crime, prior = R2(location = 0.2, what = "mode"))
print(post_crime)
fit_crime <- varsel(post_crime)
round(varsel_stats(fit_crime), digits = 2)
projs <- project(fit_crime, nv = 5)
alpha <- projs$alpha
beta <- t(projs$beta)
colnames(beta) <- names(projs$vind)
summary(beta)
post3 <- stan_glm(honcomp ~ as.factor(race) + as.factor(ses) + academic + write + math + science, data = hsbcl, prior = normal(), diagnostic_file = file.path(getwd(), "logit.csv"))
b_clogit <- bridge_sampler(post2)
b_logit <- bridge_sampler(post3)
post_prob(b_clogit, b_logit)
l <- list(log_lik(post), log_lik(post2))
w <- loo_model_weights(l)
plot(loo(post))
compare_models(loo(post), loo(post2))
length(post)
length(post2)
bayesplot::mcmc_dens(as.matrix(post)) # ask about regex_pars
View(post)
post <- stan_clogit(honcomp ~ as.factor(ses) + write + math + science, data = hsbcl, strata = pid, diagnostic_file = file.path(getwd(), "clogit.csv"))
print(post)
plot(post)
bayesplot::mcmc_dens(as.matrix(post))
gg <- pp_check(post, plotfun = "dens_overlay", nreps = 50) +
ggplot2::theme(legend.position = "bottom")
gg
PPD <- posterior_predict(post, draws = 1000)
lower <- apply(PPD, MARGIN = 2, quantile, probs = 0.25)
upper <- apply(PPD, MARGIN = 2, quantile, probs = 0.75) # how to take the mean of two columns
with(hsbcl, mean(honcomp[ses == "low"] > lower &
honcomp[ses == "low"] < upper))
post2 <- stan_clogit(honcomp ~ as.factor(race) + as.factor(hises) + academic, data = hsbcl, strata = pid, diagnostic_file = file.path(getwd(), "clogit.csv"))
l <- list(log_lik(post), log_lik(post2))
w <- loo_model_weights(l)
plot(loo(post))
compare_models(loo(post), loo(post2))
post <- stan_clogit(honcomp ~ as.factor(ses) + write + math + science, data = hsbcl, strata = pid, diagnostic_file = file.path(getwd(), "clogit.csv"))
post2 <- stan_clogit(honcomp ~ as.factor(race) + as.factor(hises) + academic, data = hsbcl, strata = pid, diagnostic_file = file.path(getwd(), "clogit2.csv"))
l <- list(log_lik(post), log_lik(post2))
w <- loo_model_weights(l)
plot(loo(post))
compare_models(loo(post), loo(post2))
post <- stan_clogit(honcomp ~ as.factor(ses) + write + math + science, data = hsbcl, strata = pid, diagnostic_file = file.path(getwd(), "clogit.csv"))
mean(lower)
mean(upper)
post2 <- stan_clogit(honcomp ~ as.factor(race) + as.factor(hises) + write, data = hsbcl, strata = pid, diagnostic_file = file.path(getwd(), "clogit2.csv"))
compare_models(loo(post), loo(post2))
w
hsbcl <- foreign::read.dta("https://stats.idre.ucla.edu/stat/stata/webbooks/logistic/hsbcl.dta")
colnames(hsbcl)
X <- model.matrix(honcomp ~ ses + write + math + science + socst, hsbcl)[, -1]
post <- stan_clogit(honcomp ~ as.factor(ses) + write + math + science + socst, data = hsbcl, strata = pid, diagnostic_file = file.path(getwd(), "clogit.csv"))
print(post)
plot(post)
bayesplot::mcmc_dens(as.matrix(post))
gg <- pp_check(post, plotfun = "dens_overlay", nreps = 50) +
ggplot2::theme(legend.position = "bottom")
gg
PPD <- posterior_predict(post, draws = 1000)
lower <- apply(PPD, MARGIN = 2, quantile, probs = 0.25)
upper <- apply(PPD, MARGIN = 2, quantile, probs = 0.75) # how to take the mean of two columns
with(hsbcl, mean(honcomp[ses == "low"] > lower &
honcomp[ses == "low"] < upper))
View(hsbcl)
baseline <- posterior_linpred(post, transform = TRUE)
nd <- model.frame(post)
nd$favorite_count <- nd$favorite_count + 5
baseline <- posterior_linpred(post, transform = TRUE)
par(mar = c(4, 4, 0, 0) + 0.2, las = 1)
hist(plus5 - baseline, prob = TRUE, xlab = "", main = "")
baseline <- posterior_linpred(post, transform = TRUE)
par(mar = c(4, 4, 0, 0) + 0.2, las = 1)
hist(baseline, prob = TRUE, xlab = "", main = "")
rstan:::rstudio_stanc("Desktop/Bayesian Statistics/Assignments/Assignment 4/hsbcl_rng.stan")
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
library(rstan)
library(rstanarm); options(mc.cores = parallel::detectCores())
library(bridgesampling)
library(projpred)
library(bayesplot)
library(loo)
set.seed(2184)
hsbcl <- foreign::read.dta("https://stats.idre.ucla.edu/stat/stata/webbooks/logistic/hsbcl.dta")
colnames(hsbcl)
X <- model.matrix(honcomp ~ ses + read + write + math + science + socst, hsbcl)[, -1]
expose_stan_functions("hsbcl_rng.stan")
test <- hsbcl_rng(S = 100, X = X)
test[1, ]
X <- model.matrix(honcomp ~ read + write + math + science + socst, hsbcl)[, -1]
test <- hsbcl_rng(S = 100, X = X)
test[1, ]
test <- hsbcl_rng(S = 1000, X = X)
test[1, ]
X <- model.matrix(honcomp ~ read + write + math + science + socst, hsbcl)[, -1]
test <- hsbcl_rng(S = 1000, X = X)
test[1, ]
text[3, ]
test[3, ]
test[1, ]
bayesplot::mcmc_dens(as.matrix(post))
post <- stan_clogit(honcomp ~  read + write + math + science + socst, data = hsbcl, strata = pid, diagnostic_file = file.path(getwd(), "clogit.csv"))
print(post)
plot(post)
bayesplot::mcmc_dens(as.matrix(post))
pp_check(post, plotfun = "dens_overlay", nreps = 10) +
ggplot2::theme(legend.position = "bottom")
nd <- model.frame(post)
nd$read <- nd$read + 10
read10 <- posterior_linpred(post, newdata = nd, transform = TRUE)
nd <- model.frame(post)
nd$read <- nd$read + 10
read10 <- posterior_linpred(post, newdata = nd, transform = TRUE)
bayesplot::mcmc_dens(as.matrix(post))
nd <- model.frame(post)
nd$read <- nd$read + 10
write10 <- posterior_linpred(post, newdata = nd, transform = TRUE)
nd <- hsbcl
nd$read <- nd$read + 10
nd <- hsbcl
for (i in 1:nrow(nd)){
nd$read[i] <- nd$read + 20
i + 2
}
nd$read - hsbcl$read
View(nd$read)
nd <- hsbcl
nd$read[, 1] <- nd$read[, 1] + 20
nd$read[1] <- nd$read[1] + 20
View(nd$read)
for (i in 1:nrow(nd)){
nd$read[i] <- nd$read[i] + 20
i + 2
}
nd <- hsbcl
for (i in seq(1, 106, 2)){
nd$read[i] <- nd$read[i] + 20
}
nd$read - hsbcl$read
seq(1, 106, 2)
View(nd$read)
nd <- hsbcl
for (i in seq(1, 106, 2)){
nd$read[i] <- nd$read[i] + 20
}
nd$read[1] <- nd$read[1] + 20
nd$read[3] <- nd$read[3] + 20
nd <- hsbcl
post_nd <- stan_clogit(honcomp ~  read + write + math + science + socst, data = hsbcl, strata = pid, diagnostic_file = file.path(getwd(), "clogit.csv"))
read10 <- posterior_linpred(post, newdata = nd, transform = TRUE)
par(mar = c(4, 4, 0, 0) + 0.2, las = 1)
hist(read10 - baseline, prob = TRUE, xlab = "Change in Probability", main = "")
nd <- hsbcl
for (i in seq(1, 106, 2)){
nd$write[i] <- nd$write[i] + 20
}
post_nd <- stan_clogit(honcomp ~  read + write + math + science + socst, data = hsbcl, strata = pid, diagnostic_file = file.path(getwd(), "clogit.csv"))
write10 <- posterior_linpred(post, newdata = nd, transform = TRUE)
par(mar = c(4, 4, 0, 0) + 0.2, las = 1)
hist(write10 - baseline, prob = TRUE, xlab = "Change in Probability", main = "")
hist(write10 - baseline, xlab = "", main = "")
write10 <- posterior_linpred(post, newdata = post_nd, transform = TRUE)
nd <- hsbcl
for (i in seq(1, 106, 2)){
nd$write[i] <- nd$write[i] + 20
}
write10 <- posterior_linpred(post, newdata = nd, transform = TRUE)
par(mar = c(4, 4, 0, 0) + 0.2, las = 1)
hist(write10 - baseline, xlab = "", main = "")
nd <- model.matrix(hsbcl)
nd <- hsbcl
for (i in seq(1, 106, 2)){
nd$write[i] <- nd$write[i] + 20
}
nd <- hsbcl
for (i in seq(1, 106, 2)){
nd$write[i] <- nd$write[i] + 20
}
post_nd <- stan_clogit(honcomp ~  read + write + math + science + socst, data = hsbcl, strata = pid, diagnostic_file = file.path(getwd(), "clogit.csv"))
write10 <- posterior_linpred(post, newdata = post_nd, transform = TRUE)
write10 <- posterior_linpred(post, newdata = as.data.frame(post_nd), transform = TRUE)
nd <- model.frame(post)
for (i in seq(1, 106, 2)){
nd$write[i] <- nd$write[i] + 20
}
write10 <- posterior_linpred(post, newdata = post_nd, transform = TRUE)
write10 <- posterior_linpred(post, newdata = nd, transform = TRUE)
nd <- post.model(post)
nd <- model.frame(post)
View(nd)
colnames(nd)[z] <- pid
colnames(nd)[z] <- "pid"
colnames(nd)[z7 <- "pid"
ds
colnames(nd)[7] <- "pid"
nd <- model.frame(post)
for (i in seq(1, 106, 2)){
nd$write[i] <- nd$write[i] + 20
}
colnames(nd)[7] <- "pid"
write10 <- posterior_linpred(post, newdata = nd, transform = TRUE)
par(mar = c(4, 4, 0, 0) + 0.2, las = 1)
hist(write10 - baseline, xlab = "", main = "")
hist(abs(write10 - baseline), xlab = "", main = "")
hist(abs(write10 - baseline), prob = TRUE, xlab = "", main = "")
hist(write10 - baseline, prob = TRUE, xlab = "", main = "")
par(mar = c(5, 5, 3, 3) + 0.2, las = 1)
hist(write10 - baseline, prob = TRUE, xlab = "", main = "")
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
library(rstan)
library(rstanarm); options(mc.cores = parallel::detectCores())
library(bridgesampling)
library(projpred)
library(bayesplot)
library(loo)
set.seed(2184)
hsbcl <- foreign::read.dta("https://stats.idre.ucla.edu/stat/stata/webbooks/logistic/hsbcl.dta")
colnames(hsbcl)
X <- model.matrix(honcomp ~ read + write + math + science + socst, hsbcl)[, -1]
expose_stan_functions("hsbcl_rng.stan")
test <- hsbcl_rng(S = 1000, X = X)
test[1, ]
post <- stan_clogit(honcomp ~  read + write + math + science + socst, data = hsbcl, strata = pid, diagnostic_file = file.path(getwd(), "clogit.csv"))
print(post)
plot(post)
bayesplot::mcmc_dens(as.matrix(post))
baseline <- posterior_linpred(post, transform = TRUE)
par(mar = c(4, 4, 0, 0) + 0.2, las = 1)
hist(baseline, prob = TRUE, xlab = "", main = "")
nd <- model.frame(post)
for (i in seq(1, 106, 2)){
nd$write[i] <- nd$write[i] + 20
}
colnames(nd)[7] <- "pid"
write10 <- posterior_linpred(post, newdata = nd, transform = TRUE)
par(mar = c(5, 5, 3, 3) + 0.2, las = 1)
hist(write10 - baseline, prob = TRUE, xlab = "", main = "")
pp_check(post, plotfun = "dens_overlay", nreps = 10) +
ggplot2::theme(legend.position = "bottom")
PPD <- posterior_predict(post, draws = 1000)
lower <- apply(PPD, MARGIN = 2, quantile, probs = 0.25)
upper <- apply(PPD, MARGIN = 2, quantile, probs = 0.75)
with(hsbcl, mean(honcomp > lower &
honcomp < upper))
post2 <- stan_clogit(honcomp ~ as.factor(race) + as.factor(hises) + write, data = hsbcl, strata = pid, diagnostic_file = file.path(getwd(), "clogit2.csv"))
l <- list(log_lik(post), log_lik(post2))
loo_model_weights(l)
plot(loo(post))
plot(loo(post2))
compare_models(loo(post), loo(post2))
post3 <- stan_glm(honcomp ~ as.factor(race) + as.factor(ses) + academic + write + math + science, data = hsbcl, prior = normal(), diagnostic_file = file.path(getwd(), "logit.csv"))
b_clogit <- bridge_sampler(post2)
b_logit <- bridge_sampler(post3)
post_prob(b_clogit, b_logit)
ROOT <- "https://archive.ics.uci.edu/ml/machine-learning-databases/"
crime <- read.csv(paste0(ROOT, "communities/communities.data"),
header = FALSE, na.strings = "?")
colnames(crime) <- read.table(paste0(ROOT, "communities/communities.names"),
skip = 75, nrows = ncol(crime))[,2]
print(post_crime)
post_crime <- stan_lm(ViolentCrimesPerPop ~ population + racepctblack + agePct12t29 + medIncome + NumUnderPov + PctUnemployed + MalePctDivorce + PctWorkMom + HousVacant + NumStreet + PolicReqPerOffic + PolicCars + NumKindsDrugsSeiz +  agePct12t29*PctUnemployed + agePct12t29^2, data = crime, prior = R2(location = 0.2, what = "mode"))
print(post_crime)
fit_crime <- varsel(post_crime)
round(varsel_stats(fit_crime), digits = 2)
projs <- project(fit_crime, nv = 5)
alpha <- projs$alpha
beta <- t(projs$beta)
colnames(beta) <- names(projs$vind)
summary(beta)
test <- hsbcl_rng(S = 1000, X = X)
test[1, ]
print(post)
baseline <- posterior_linpred(post, transform = TRUE)
par(mar = c(4, 4, 0, 0) + 0.2, las = 1)
hist(baseline, prob = TRUE, xlab = "", main = "")
nd <- model.frame(post)
for (i in seq(1, 106, 2)){
nd$write[i] <- nd$write[i] + 20
}
colnames(nd)[7] <- "pid"
write10 <- posterior_linpred(post, newdata = nd, transform = TRUE)
par(mar = c(5, 5, 3, 3) + 0.2, las = 1)
hist(write10 - baseline, prob = TRUE, xlab = "", main = "")
plot(post)
bayesplot::mcmc_dens(as.matrix(post))
pp_check(post, plotfun = "dens_overlay", nreps = 10) +
ggplot2::theme(legend.position = "bottom")
PPD <- posterior_predict(post, draws = 1000)
lower <- apply(PPD, MARGIN = 2, quantile, probs = 0.25)
upper <- apply(PPD, MARGIN = 2, quantile, probs = 0.75)
with(hsbcl, mean(honcomp > lower &
honcomp < upper))
post2 <- stan_clogit(honcomp ~ write + science, data = hsbcl, strata = pid, diagnostic_file = file.path(getwd(), "clogit2.csv"))
l <- list(log_lik(post), log_lik(post2))
loo_model_weights(l)
plot(loo(post))
plot(loo(post2))
compare_models(loo(post), loo(post2))
library(ggplot2)
ggplot(hsbcl, (aes(x = write, y = science))) +
geom_point()
ggplot(hsbcl, (aes(x = write, y = science))) +
geom_point(shape = factor(honcomp))
ggplot(hsbcl, (aes(x = write, y = science))) +
geom_point(shape = factor(honcomp))
ggplot(hsbcl, (aes(x = write, y = science))) +
geom_point(shape = honcomp)
ggplot(hsbcl, (aes(x = write, y = science))) +
geom_point(shape = "honcomp")
ggplot(hsbcl, (aes(x = write, y = science))) +
geom_point(color = honcomp)
ggplot(hsbcl, (aes(x = write, y = science))) +
geom_point(color = hsbcl$honcomp)
View(hsbcl)
ggplot(hsbcl, (aes(x = write, y = science))) +
geom_point(aes(shape = honcomp))
ggplot(hsbcl, (aes(x = write, y = science))) +
geom_point(aes(shape = factor(honcomp)))
ggplot(hsbcl, (aes(x = write, y = science))) +
geom_point(aes(shape = factor(honcomp))) +
geom_line()
ggplot(hsbcl, (aes(x = write, y = science))) +
geom_point(aes(shape = factor(honcomp))) +
geom_smooth
ggplot(hsbcl, (aes(x = write, y = science))) +
geom_point(aes(shape = factor(honcomp))) +
geom_smooth()
ggplot(hsbcl, (aes(x = write, y = science))) +
geom_point(aes(shape = factor(honcomp))) +
geom_smooth(method= lm, se = FALSE)
ggplot(hsbcl, (aes(x = science, y = write))) +
geom_point(aes(shape = factor(honcomp))) +
geom_smooth(method= lm, se = FALSE)
ggplot(hsbcl, (aes(x = science, y = write))) +
geom_point(aes(shape = factor(honcomp))) +
geom_smooth(se = FALSE)
print(post2)
baseline2 <- posterior_linpred(post, transform = TRUE)
par(mar = c(4, 4, 0, 0) + 0.2, las = 1)
hist(baseline, prob = TRUE, xlab = "", main = "")
hist(write10 - baseline, prob = TRUE, xlab = "Changes in Probability with Increase in Write Score", main = "")
compare_models(post, post2)
library(knitr)
include_graphics(., "transformations.jpg")
setwd("/Users/Nicole/Desktop/Bayesian Statistics/Assignments/Assignment 4")
include_graphics(., "transformations.jpg")
include_graphics("./transformations.jpg")
include_graphics("./transformation.jpg")
movie_UI         <- as.matrix(movie_UI)
movie_sim_weight <- matrix(NA, nrow = nrow(movie_UI), ncol = nrow(movie_UI))
# Can calculate Pearson correlation between two rows of UI matrix as:
rowA <- movie_UI[1, ]
rowB <- movie_UI[2, ]
cor(rowA, rowB, method = 'pearson', use = "pairwise.complete.obs")
# Another way:
joint_values <- !is.na(rowA) & !is.na(rowB)
cor(rowA[joint_values], rowB[joint_values], method = 'pearson')
# First fill in row 1 of the similarity matrix using apply
system.time(vec1 <- apply(movie_UI, 1, cor, movie_UI[1, ], method = 'pearson', use = "pairwise.complete.obs"))
# Now fill in row 1 of the similarity matrix looping over the columns and
# calculating pairwise correlations
long.way <- function(row.num) {
for(i in 1:nrow(movie_UI)) {
movie_sim_weight[row.num, i] <- cor(movie_UI[i, ], movie_UI[row.num, ], method = 'pearson', use = "pairwise.complete.obs")
}
system.time(long.way(1))
# Calculate the full weights on the movie data
# The below took 87 minutes on my Macbook, 35 on my iMac
movie_sim <- calc_weight(movie_UI)
save(movie_sim, file = "movie_sim.RData")
# Calculate the full weights on the MS data
# The below took 30 minutes on my Macbook and 14 on my iMac
MS_sim <- calc_weight(MS_UI)
save(MS_sim, file = "MS_sim.RData")
setwd("/Users/Nicole/Documents/GitHub/project-3-algorithms-project-4-algorithms-group-4/doc")
knitr::opts_chunk$set(echo = TRUE)
setwd("/Users/Nicole/Documents/GitHub/project-3-algorithms-project-4-algorithms-group-4/doc")
load(MS_UI, file = "../data/MS_UI.RData")
load(file = "../data/MS_UI.RData")
View(MS_UI)
load(file = "../data/movie_UI.RData")
View(movie_UI)
structure(movie_UI)
str(movie_UI)
head(movie_UI)
visit_nums <- rowSums(MS_UI ! = 0)
visit_nums <- rowSums(MS_UI, na.rm = TRUE)
total_ratings <- rowSums(movie_UI, na.rm = TRUE)
View(visit_nums)
movie_UI <- as.matrix(movie_UI)
movie_sim_weight <- matrix(NA, nrow = nrow(movie_UI), ncol = nrow(movie_UI))
movie_sim <- calc_weight(movie_UI)
setwd("/Users/Nicole/Documents/GitHub/project-3-algorithms-project-4-algorithms-group-4/doc")
source("../lib/functions.R")
movie_sim <- calc_weight(movie_UI)
save(movie_sim, file = "movie_sim.RData")
movie_sim <- calc_weight(movie_UI)
MS_sim <- calc_weight(MS_UI)
save(MS_sim, file = "../data/MS_sim.RData")
MS_pred <- pred_matrix(MS_UI, MS_sim) # filled in prediction matrix
save(MS_pred, file = "MS_pred.RData")
movie_pred <- pred_matrix(movie_UI, movie_sim)
save(movie_pred, file = "movie_pred.RData")
install.packages("EMCluster")
library(EMCluster)
view(e.step)
View(e.step)
MS_test <- read.csv("../data/MS_sample/data_test.csv", as.is = TRUE, header = TRUE)
MS_test <- MS_test[, 2:4]
MS_UI <- MS_data_transform(MS_test)
save(MS_UI_test, file = "../data/MS_UI.RData")
MS_UI <- MS_data_transform(MS_test)
MS_test <- read.csv("../data/MS_sample/data_test.csv", as.is = TRUE, header = TRUE)
MS_test <- MS_test[, 2:4]
# Below takes 2.17 minutes
MS_UI_test <- MS_data_transform(MS_test)
save(MS_UI_test, file = "../data/MS_UI.RData")
data <- movie_UI[1:500, ]
